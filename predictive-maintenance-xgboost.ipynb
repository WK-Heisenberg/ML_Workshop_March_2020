{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Predictive Maintainance MVP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run this notebook after you have ran Dataset_preprocess.ipynb to create a cleaned dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we train an ML model to predict whether a part is faulty or not based on sensor readings from the part. For training, we use a dataset which is adapted from a real predictive maintenance use case. The columns and rows have been anonymized, but the overall statistics of the dataset has been preserved. This will allow you to see some of the typical challenges that arise when dealing with ML for predictive maintenance.\n",
    "\n",
    "We will go over the key aspects of a typical data science pipeline:\n",
    "\n",
    "1. data ingest\n",
    "2. data exploration <br/>\n",
    "3. model training <br/>\n",
    "4. model deployment <br/>\n",
    "\n",
    "Here we train an XGBoost model, using Amazon SageMaker's built in algorithms to predict whether a part is faulty or not in assembly line for predictive maintainance. Once the faulty part is found, it will be removed from the line and taken for repair.\n",
    "\n",
    "Instead of deploying a live endpoint here, we will deploy the model locally on the Greengrass core. But to test the model, we will test the model predictions on a test dataset and plot relevant metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Import libraries and get data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# bucket = 'iot-ml-predictive-maintenance' #Replace with the bucket name created for you by CloudFormation or any other bucket\n",
    "# # if you are just running the notebook, not the entire lab\n",
    "prefix = 'xgbdata'\n",
    "LOCAL_DIR = 'training_data'\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Path to upload the trained model\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "xgb_upload_location = os.path.join('s3://{}/{}'.format(bucket, 'xgb'))\n",
    "print(xgb_upload_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the latest XGBoost container from ECR\n",
    "region = sagemaker_session.boto_region_name\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(region, 'xgboost', '0.90-1')\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training data doesn't have any column name headers so lets include those first\n",
    "with open('cols.txt', 'r') as f:\n",
    "    cols = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data directly locally\n",
    "import pandas as pd\n",
    "\n",
    "DATANAME = 'train.csv'\n",
    "\n",
    "datorig = pd.read_csv('{}/{}'.format(LOCAL_DIR, DATANAME), names = cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datorig.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of 2 parts:\n",
    "\n",
    "1. Response: this is the faulty (1) or not faulty (0) signal. <br/>\n",
    "2. Sensor readings: the remaining 168 columns correspond to Sensor readings.\n",
    "\n",
    "Note the large number of 0s in the dataset. This is because not all sensors fire at the same time, and each reading only comes from a subset of the sensors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building an ML model, let's go ahead and explore the dataset and look for some correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance\n",
    "One of the first things you notice in predictive maintenance is CLASS IMBALANCE.\n",
    "\n",
    "CLASS IMBALANCE occurs when one class (in this case faulty labels) is much less prevalent than the not faulty label.\n",
    "\n",
    "This is a problem for ML models as this means that the model may not see enough examples of the faulty class to train accurately. Seen another way, this means that a model that always predicts a label to be not faulty is 98.4% accurate!\n",
    "\n",
    "Our ML model will need to beat this accuracy to be useful from a business perspective. There are a number of ways for dealing with imbalanced classification problems -- upsampling, downsampling, SMOTE to name a few. For this POC we will not use these approaches and train a minimal viable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(datorig.Response)\n",
    "print(\"Percent of Faulty Examples = {:.1f}\".format(len(datorig[datorig['Response']==1])/len(datorig)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "\n",
    "Next let's extract some correlations between the Response label and the Sensor features. Since we have so many features, we can plot a heatmap for the correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = datorig.corr()\n",
    "\n",
    "plt.figure(figsize= (10, 10))\n",
    "sns.heatmap(np.abs(corr))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the correlation heatmap above: what do you notice?\n",
    "\n",
    "There are striking blocks of high correlations amidst relatively little correlations between other features. \n",
    "Physically these blocks could be sensors that are all firing at once on a single assembly line, or assigned to a single part. Our ML model must be able to deal with these strong and weak correlations well. A linear model may not be able to perform well when features are strongly correlated. For this reason, we choose a tree based gradient boosting model like XGBoost.\n",
    "\n",
    "Traditionally, we might want to consider methods like PCA to perform some dimensionality reduction, but this comes at a cost of interpretability. In our factory, we want to determine which sensor is giving the anomalous signal corresponding to the faulty part, and PCA will mix the sensor signals together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify what sensors correlate strongly with the faulty label\n",
    "index_list = list(corr['Response'].dropna().index)\n",
    "val_list = np.argsort(np.abs(corr['Response'].dropna().values))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most corelated variables to the Response label. The response variable is ofcourse most correlated with itself \n",
    "#and removed\n",
    "top_corrs = [index_list[x] for x in val_list[:5]]\n",
    "top_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceddat = datorig[top_corrs]\n",
    "reduceddat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot how the top correlated sensor readings are correlated with each other and the Faulty and Not Faulty Labels\n",
    "g = sns.PairGrid(reduceddat, hue=\"Response\")\n",
    "g.map_diag(plt.hist)\n",
    "g.map_offdiag(plt.scatter)\n",
    "g.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Model Training and Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having explored the dataset some, we can now build a model.\n",
    "Our guiding principles for Model choice are as follows:\n",
    "\n",
    "1. There are multiple sensors with weak correlations to the final output variable <br/>\n",
    "2. Outputs are highly skewed and imbalanced, so our baseline model already has 98.4% accuracy. The ML model will need to do better to drive business value <br/>\n",
    "3. Sensor data may itself be correlated with each other and not all sensors may fire at once <br/>\n",
    "\n",
    "A linear model may not work as well in this situation as the outputs are imbalanced and in real life sensor data may be highly correlated. For this reason, we choose a gradient boosting based tree model called XGBoost. \n",
    "\n",
    "SageMaker has a built in implementation of the XGBoost algorithm designed to work at scale. The default data type for XGBoost is LIBSVM format. But our data is in csv and XGBoost also accepts a csv input but it needs to be specified in the 'content_type' variable. We do this first.\n",
    "\n",
    "Next we train a model: This should take less than 5 minutes and incur about 1 minute of training cost. Remember that SageMaker charges you for the time it takes the train and the infrastructure you train on. There are no upfront charges or recurring costs. Once training is complete, SageMaker tears it down automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NExt we need to push the training and test data to S3\n",
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "\n",
    "sagemaker_session.upload_data(path='training_data', bucket=bucket, key_prefix=train_channel)\n",
    "sagemaker_session.upload_data(path='test_data', bucket=bucket, key_prefix=validation_channel)\n",
    "\n",
    "#s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "#s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)\n",
    "s3_train_channel = sagemaker.session.s3_input('s3://{}/{}'.format(bucket, train_channel), content_type ='csv')\n",
    "s3_valid_channel = sagemaker.session.s3_input('s3://{}/{}'.format(bucket, validation_channel), content_type ='csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.c4.8xlarge',\n",
    "                                    output_path=xgb_upload_location,\n",
    "                                    sagemaker_session=sagemaker_session)\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)\n",
    "\n",
    "xgb.fit({'train': s3_train_channel, 'validation': s3_valid_channel})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Model deployment and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several options to deploy the model:\n",
    "\n",
    "1. Live Endpoint: this approach is suitable for low latency inference against live data in the cloud. Since we want to make inferences in our factory environment, we don't choose this option. <br/>\n",
    "\n",
    "\n",
    "2. Batch Transform: to test out our model accuracy, we run inferences against some test data. As our dataset is small, the test set here is just the training set + validation set. In reality, this should be completely unseen data, but this will suffice for our MVP. <br/>\n",
    "\n",
    "\n",
    "3. Deploy on Greengrass: Instead of deploying a live endpoint in the AWS Cloud, we will deploy the model locally on our Greengrass core. Follow the steps in the lab to accomplish this. <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Batch Transform "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of deploying a live endpoint, let's run a Batch Transform job to test the model accuracy and other metrics on the entire dataset. This dataset is saved locally, so we need to first port it over to S3.\n",
    "\n",
    "\n",
    "Once the dataset is in S3, we can call SageMaker Batch Transform to perform inference on the entire dataset and save the output to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the Response column from the dataset.\n",
    "test_set = pd.read_csv('rawdataset.csv')\n",
    "resp = test_set['0']\n",
    "test_set = test_set.drop(columns = ['0'])\n",
    "test_set.to_csv('test.csv', index =False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_channel = prefix + '/test'\n",
    "sagemaker_session.upload_data('test.csv', bucket=bucket, key_prefix=test_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the batch transform job. Specify the input file location and point batch transform to a path for storing the model outputs.\n",
    "\n",
    "This might take some time again as SageMaker needs to provision the infrastructure needed to perform the batch transform, copy the model artifacts from the trained model s3 path, copy the data to perform batch inferences on and finally, run the Batch transform job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_input = 's3://{}/{}'.format(bucket, test_channel) # The location of the test dataset\n",
    "\n",
    "batch_output = 's3://{}/{}/batch-inference'.format(bucket, test_channel) # The location to store the results of the batch transform job\n",
    "\n",
    "transformer = xgb.transformer(instance_count=1, instance_type='ml.m4.xlarge', output_path=batch_output)\n",
    "\n",
    "transformer.transform(data=batch_input, data_type='S3Prefix', content_type='text/csv', split_type='Line')\n",
    "\n",
    "try:\n",
    "    transformer.wait()\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's download the inference into a local directory\n",
    "data_dir = './data/inference'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "!aws s3 cp --recursive $transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)\n",
    "y_vals = np.round(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics and Economics\n",
    "\n",
    "Lets get some model metrics.\n",
    "\n",
    "From a business perspective, we need to consider more than just the model accuracy but let's get that first.\n",
    "\n",
    "Two other metrics to look at are precision and recall. How do these manifest themselves in IoT Predictive maintenance?\n",
    "\n",
    "Precision is a measure of the number of false positives. High precision indicates low false positives. The added cost of high false positives is that the factory engineers and workers have to spend time and money troubleshooting and performing maintenance when its not required.\n",
    "\n",
    "Imagine the other situation: if the part is actually in need of maintenance and our model predicts that it is fine. \n",
    "In IoT settings, particularly in heavy industries, a large cost is incurred when there is \"unexpected downtime\". Especially for mission critical equipment, this can shut down the entire site. A high recall score (low false negatives) will help minimize this as it will ensure that when a part *is* in need of maintenance, it is flagged.\n",
    "\n",
    "An understanding of precision and recall must be tied in with the economics of the particular use case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Accuracy = {} %\".format(accuracy_score(resp.values, y_vals)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the baseline model was 98.4% accurate. We are getting 99.75% which beats the baseline accuracy with our XGBoost model. But the business may care more about Recall and Precision. Let's extract those next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(resp.values, y_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8, 8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "     # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes)\n",
    "    plt.tick_params(labelsize=15)  \n",
    "    plt.xlabel('Predicted label', fontsize=18)\n",
    "    plt.ylabel('True label',fontsize =18)\n",
    "    plt.title(title, fontsize=18)\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\", fontsize=20,\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(resp.values, y_vals, classes=['Normal', 'Faulty'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is not perfect but does much better than the naive model with 98.4% accuracy. What this means is that although the model still misses some examples of faulty labels, it correctly captures a large number of them that the naive model would not be able to.\n",
    "\n",
    "From a business standpoint, the business now has a much smaller number of recalled parts (883), at the expense of only 30 parts which the model incorrectly classified as Faulty, even though they were actually okay. It is these tradeoffs between business metrics and machine learning that requires multiple stakeholders to regularly engage in order to achieve good results.\n",
    "\n",
    "We can now deploy this model on to Greengrass.\n",
    "\n",
    "Go back to the predictive maintenance tutorial to continue building out this use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step, we will use SageMaker Neo to reduce the size of the ML model we have trained. Neo minimizes models to run up to twice as fast, with no loss in accuracy. This can be crucial for deploying on edge devices such as a RaspberryPi, NVIDIA Jetson Nano etc. Here we will compile the model for deploying on an EC2 instance we're using to represent Greengrass.\n",
    "\n",
    "\n",
    "As an exercise, once this model is trained, deploy this to your Greengrass Core and tag it with the Lambda function as shown in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = xgb\n",
    "try:\n",
    "    xgb.create_model()._neo_image_account(sagemaker_session.boto_region_name)\n",
    "except:\n",
    "    print('Neo is not currently supported in', sagemaker_session.boto_region_name)\n",
    "else:\n",
    "    output_path = '/'.join(xgb.output_path.split('/')[:-1]) + '/neo'\n",
    "    compiled_model = xgb.compile_model(target_instance_family='ml_m4', \n",
    "                                   input_shape={'data':[1, 168]},\n",
    "                                   role=role,\n",
    "                                   framework='xgboost',\n",
    "                                   framework_version='0.90-1',\n",
    "                                   output_path=output_path)\n",
    "    compiled_model.name = 'deployed-xgboost-customer-churn'\n",
    "    compiled_model.image = get_image_uri(region, 'xgboost-neo', repo_version='latest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a simple function to get the Model size in both cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(estimator):\n",
    "    out= !aws s3 ls {estimator.model_data} --human-readable\n",
    "    return out[0].split(' ')[-3]+' MB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [xgb, compiled_model] \n",
    "targets = ['Original', 'Neo for ml.m4']\n",
    "locations = [e.model_data for e in estimators]\n",
    "sizes = [get_model_size(e) for e in estimators]\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "pd.DataFrame(list(zip(targets,locations,sizes)), columns =['Targets', 'Locations','Sizes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that SageMaker Neo reduces the model size dramatically, which can make it easier for deploying on edge devides for limited RAM and Memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:environment/datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
